<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 神经元网络Fokker Planck方程 | Kai Chen 陈开 </title> <meta name="author" content="Kai Chen 陈开"> <meta name="description" content="Personal website of Kai Chen. Here, you may find its ideas about life, research, and technical stuffs. ENJOY the life! "> <meta name="keywords" content="jekyll, academic-website, computational-neuroscience"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo-w.png?d0ca8801e30659248d8579510bc77dc6"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://neoneuron.github.io/zh-cn/blog/2023/FPE-and-NMM/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "神经元网络Fokker Planck方程",
            "description": "",
            "published": "February 10, 2023",
            "authors": [
              
              {
                "author": "Kai Chen",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/zh-cn/"> <span class="font-weight-bold">Kai</span> Chen 陈开 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/zh-cn/">简介 </a> </li> <li class="nav-item "> <a class="nav-link" href="/zh-cn/cv/">简历 </a> </li> <li class="nav-item "> <a class="nav-link" href="/zh-cn/publications/">论文 </a> </li> <li class="nav-item "> <a class="nav-link" href="/zh-cn/teaching/">教学 </a> </li> <li class="nav-item active"> <a class="nav-link" href="/zh-cn/blog/">博客 </a> </li> <li class="nav-item "> <a class="nav-link" href="/zh-cn/repositories/">代码 </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/2023/FPE-and-NMM/"> <span class="fi fi-us"></span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>神经元网络Fokker Planck方程</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <div class="l-page-outset"> 给定$N$个兴奋性LIF神经元，将他们依照一个固定的概率$p$随机链接构成一个网络，其中每个神经元的细胞跨膜电压可以用如下方程描述： $$ \begin{equation} \begin{aligned} \frac{dV_i}{dt} = -\frac{g_l}{C_m}(V_i-V_l) + \frac{I_\mathrm{ext}}{C_m} + \sum_j^N\sum_k w_{ij}\delta(t-t_j^k), \end{aligned} \label{eq:lif} \end{equation} $$ 其中$g_l$，$C_m$，$V_l$分别为神经元的电导，电容和漏电电位，$I_\mathrm{ext}$为外部输入电流，$w_{ij}$为神经元$i$和$j$之间的作用强度，即神经元$j$接收到来自神经元$i$的一个脉冲输入后电压的将上升$w_{ij}$，而$t_j^k$为神经元$j$的第$k$次脉冲发放时间。下面我们假设，网络中所有的神经元都是接受相同的电流输入，且不同神经元之间的作用强度$w_{ij}= w$，均相同。由于所有神经元在网络中的地位都是相同的，与其通过$N$个相互耦合的常微分方程来刻画网络中所有神经元在任意$t$时刻的电压状态$V_i$，不如统计一下每个$t$时刻处于不同电压值的神经元的数量。若将LIF神经元的静息电位$V_\text{r}$到阈值电位$V_\theta$，平均分分成长度为$\Delta V$的等间隔小区间，统计$t$时刻电压值落在$[V-\Delta V/2,V+\Delta V/2)$区间内的神经元个数，$n(V,t)$，则落在该区间内的神经元数量的概率为： $$ \begin{equation} P(V,t) = \frac{n(V,t)}{N}. \end{equation} $$ 根据最朴素的神经元数目守恒的原则，我们下面简单分析一下，在$t+\Delta t$时刻，$P(V,t+\Delta t)$将会是多少。神经元膜电位的变化由\ref{eq:lif}决定，因此区间$[V-\Delta V/2, V+\Delta V/2)$内神经元数目的增加由三个部分贡献。第一，从$[V-3\Delta V/2, V-\Delta V/2)$转移到$[V-\Delta V/2, V+\Delta V/2)$的神经元数量，由外加电流$I_\mathrm{ext}$的强度决定，可以由如下方程描述： $$ \begin{equation} P(V-\Delta V, t)\frac{I_\mathrm{ext}}{C_m}\Delta t. \end{equation} $$ 第二，从$[V-\Delta V/2, V+\Delta V/2)$转移到$[V+\Delta V/2, V+3\Delta V/2)$的神经元数量，由神经元漏电流的强度与当前神经元的膜电位决定，可以由如下方程描述： $$ \begin{equation} P(V+\Delta V, t)\frac{g_l}{C_m}(V+\Delta V-V_l)\Delta t. \end{equation} $$ 第三，其他神经元放电所产生的突触电流，公式\ref{eq:lif}中的等式右端第三项。由于网络中神经元的发放时间是随机的，不妨将其视为平均放电率相同的Poisson过程。由此，我们统计平均单位时间内每个神经元接收到的突触发放电流数目为$\nu(t)$，其中 $$ \nu(t) = \frac{1}{\Delta}\int\limits_{t-\Delta t/2}^{t+\Delta t/2}\sum_{k=1}^N\delta(\tau-t_k)d\tau. $$ 由于突触后膜电位在接收到输入后会瞬时增加$w$，因此，突触输入将使得$[V-\Delta V/2, V+\Delta V/2)$区间内神经元数目增加： $$ \begin{equation} \nu(t)\Delta t \cdot P(V-w, t)\cdot \Delta V. \end{equation} $$ 类似的，从$[V-\Delta V/2, V+\Delta V/2]$流出的神经元数量，如下方程描述： $$ \begin{equation} \begin{aligned} \left[V-\frac{\Delta V}{2}, V+\frac{\Delta V}{2}\right)\to\left[V-\frac{3\Delta V}{2}, V-\frac{\Delta V}{2}\right): &amp;\quad P(V, t)\frac{g_l}{C_m}(V-V_l)\Delta t,\\ \left[V-\frac{\Delta V}{2}, V+\frac{\Delta V}{2}\right)\to\left[V+\frac{\Delta V}{2}, V+\frac{3\Delta V}{2}\right): &amp;\quad P(V, t)\frac{I_\mathrm{ext}}{C_m}\Delta t,\\ \left[V-\frac{\Delta V}{2}, V+\frac{\Delta V}{2}\right)\to\left[V+w-\frac{\Delta V}{2}, V+w+\frac{\Delta V}{2}\right): &amp;\quad \nu(t)\Delta t \cdot P(V, t)\Delta V.\\ \end{aligned} \end{equation} $$ <div class="row"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/figures/FPE-480.webp 480w,/assets/figures/FPE-800.webp 800w,/assets/figures/FPE-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/figures/FPE.png" class="img-fluid rounded" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p style="text-align:center"> <b>主方程</b>。主要描述位于膜电位区间$\left[V-\Delta V/2,V+\Delta V/2\right]$中神经元数目的概率密度在$t$时刻的变化情况。</p> 因此，我们可以得到如下方程描述的神经元数目的变化： $$ \begin{equation} \begin{aligned} \left[P(V, t+\Delta t) - P(V, t)\right]\Delta V &amp;= \text{流入区间的神经元数目}-\text{流出区间的神经元数目}\\ &amp;=P(V-\Delta V, t)\frac{I_\mathrm{ext}}{C_m}\Delta t+ P(V+\Delta V, t)\frac{g_l}{C_m}(V+\Delta V-V_l)\Delta t + \nu(t)\Delta t \cdot P(V-w, t)\Delta V \\ &amp;\quad- P(V, t)\frac{g_l}{C_m}(V-V_l)\Delta t - P(V, t)\frac{I_\mathrm{ext}}{C_m}\Delta t-\nu(t)\Delta t \cdot P(V, t)\Delta V\\ &amp;=\left[P(V-\Delta V, t)-P(V,t)\right]\frac{I_\mathrm{ext}}{C_m}\Delta t+ \left[P(V+\Delta V, t)f(V+\Delta V)-P(V,t)f(V)\right]\Delta t \\ &amp;\quad+ \nu(t)\Delta t \Delta V \cdot \left[P(V-w, t) - P(V, t)\right] \end{aligned} \end{equation} $$ 其中$f(V) =g_l(V-V_l)/C_m$。移项整理得到 $$ \begin{equation} \begin{aligned} \frac{\left[P(V, t+\Delta t) - P(V, t)\right]}{\Delta t} &amp;=\frac{\left[P(V-\Delta V, t)-P(V,t)\right]}{\Delta V}\frac{I_\mathrm{ext}}{C_m}+ \frac{\left[P(V+\Delta V, t)f(V+\Delta V)-P(V,t)f(V)\right]}{\Delta V} \\ &amp;\quad+ \nu(t) \cdot \left[P(V-w, t) - P(V, t)\right]. \end{aligned} \label{equ:master} \end{equation} $$ 至此，我们得到了对于电压$V$取值范围内有限离散划分与时间不长$\Delta t$下的主方程(Master equation)。而神经元膜电压是一个连续取值的变量，因此，我们可以讲方程\ref{equ:master}推广到连续形式，即当神经元数目充分大，且电压划分足够密时，$N\to\infty$，$\Delta V\to 0$，我们可以将方程\ref{equ:master}中的$P(V, t)$渐进收敛为膜电压的概率密度函数$p(V,t)$。同时，我们令时间不长$\Delta t\to 0$，则方程\ref{equ:master}中的离散差分变为微分，即可的： $$ \begin{equation} \frac{\partial p(V, t)}{\partial t} = \frac{\partial}{\partial V} \left[\left(f(V)-\frac{I_\mathrm{ext}}{C_m}\right)p(V, t)\right]+ \nu(t) \cdot \left[p(V-w, t) - p(V, t)\right]. \label{equ:master_dev} \end{equation} $$ 方程\ref{equ:master_dev}描述了膜电压概率密度函数的微分方程。其中等式右端第一项为描述了神经元漏电流以及外界连续电流输入对于$V$的分布额影响，第二项描述了网络内神经元随机放电并相互作用所产生的对于膜电压的影响。另外，由于大脑皮层中神经元之间往往存在成百上千个突触连接，而单个突触单个脉冲放电引起的突触后膜电位改变(EPSP/IPSP)，模型中的$w$，相较于膜电位的取值范围，可以视为小量。因此，我们可以运用扩散近似，关于$w$为小量，泰勒展开方程\ref{equ:master_dev}中$P(V-w,t)$右端第二项至二阶，即 $$ \begin{equation} p(V-w, t) = p(V, t) - \frac{\partial p(V, t)}{\partial V} w + \frac{1}{2} \frac{\partial^2 p(V, t)}{\partial V^2} w^2 + \mathcal{O}(w^3) \end{equation} $$ 将上式带入方程\ref{equ:master_dev}并省略三阶小量$\mathcal{O}(w^3)$，得到 $$ \begin{equation} \frac{\partial p(V, t)}{\partial t} = \frac{\partial}{\partial V} \left[\left(f(V)-\frac{I_\mathrm{ext}}{C_m}-\nu(t)w\right)p(V, t)\right]+ \frac{\nu(t)w^2}{2} \frac{\partial^2}{\partial V^2} p(V, t). \label{equ:fpe} \end{equation} $$ 方程\ref{equ:fpe}便是著名的Fokker-Planck方程(FPE)的一维形式。最早由Adriaan Fokker和Max Planck于1914和1917年提出，用于描述统计物理中，流体粒子在随机力和牵引力的作用下，粒子数概率密度函数在平衡状态附近演化的偏微分方程<d-cite key="fokker1914mittlere,risken1996fokkerplanck"></d-cite>。而在神经科学领域，FPE被用于描述神经元膜电位$V$的演化<d-cite key="deco2008dynamic,breakspear2017dynamic"></d-cite>。FPE方程右端第一项为描述了神经元漏电流，外界连续电流输入，以及网络内神经元相互作用的平均效应对于$V$的分布额影响，通常称之为对流项。第二项描述了网络内神经元随机放电的相互作用所产生的对于膜电压涨落的影响，称之为扩散项。 对于LIF神经元模型，即便在扩散近似的极限条件下，$p(V,t)$仍然存在不连续的情况，即当$V=V_\theta$时，神经元将产生动作电位并重置电压值为$V_\mathrm{r}$。因此，$p(V_\theta,t)$存在神经元数目减少，其速率为神经元的平均放电率，即$\left.\frac{\partial p}{\partial t}\right|_{V=V_\theta}=-\left.\frac{\partial \boldsymbol{J}}{\partial V}\right|_{V=V_\theta}+A(t)$，其中，$A(t)$为神经元的平均放电率。与此同时，由于膜电位重置的机制，将有等量的神经元在$V=V_\mathrm{r}$处补充。因此，我们需要方程\ref{equ:fpe}进行修正，添加LIF发放重置机制对于$p(V,t)$的影响： $$ \begin{equation} \begin{aligned} \frac{\partial p(V, t)}{\partial t} &amp;= \frac{\partial}{\partial V} \left[\left(f(V)-\frac{I_\mathrm{ext}}{C_m}-\nu(t)w\right)p(V, t)\right]+ \frac{\nu(t)w^2}{2} \frac{\partial^2}{\partial V^2} p(V, t)\\ &amp;\quad + A(t) \delta\left(V-V_\mathrm{r}\right) - A(t)\delta\left(V-V_\theta\right). \end{aligned} \label{equ:fpe_lif} \end{equation} $$ 根据LIF神经元的发放重置机制，易知LIF神经元的膜电位不会超过$V_\theta$，即当$V&gt;V_\theta$时，$p(V,t)=0$。另外，根据扩散极限的限制，我们可以得知当$V=V_\theta$时，$p(V,t)=0$。因此，根据上述边界条件并结合适当的初值条件，我们可以通过解析或数值方法求解方程\ref{equ:fpe_lif}，得到膜电压概率密度函数$p(V,t)$，神经元平均放电率$A(t)$的解。 根据上文的讨论，我们发现FPE将神经网络包含$\mathcal{O}(N)$自由度的庞大高维动力系统简化成一个仅包含两个变量的一维偏微分方程系统。这种模型简化大大降低了模型的复杂度，让我们可以复杂的网络LIF网络动力学有了直观的理解。同时，我们注意到上述FPE的基于两个简单假设：一，网络内神经元全为兴奋性的基于电流的LIF神经元；二，神经元之间的连接权重相同，拓扑上随机连接，没有空间结构的差异。为了更好的符合皮层真实神经元网络的特点，我们需要对于更一般的FPE模型，例如引入基于电导的神经元模型<d-cite key="cai2006kinetica"></d-cite>，考虑小世界网络或无标度网络等更符合生物神经网络特点的网络连接结构等。 </div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2023-02-10-fpe.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ©版权 2025 Kai Chen 陈开. 网页引擎<a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>, 模版<a href="https://github.com/george-gca/multi-language-al-folio" rel="external nofollow noopener" target="_blank">multi-language-al-folio</a>, 搭建于<a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. 最近更新: : 2025 年 02月 12日 . </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-QB3MTH4R4K"></script> <script defer src="/assets/js/google-analytics-setup.js?12374742c4b1801ba82226e617af7e2d"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>