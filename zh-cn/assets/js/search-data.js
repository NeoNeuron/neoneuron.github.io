
const currentUrl = window.location.href;
const siteUrl = "https://neoneuron.github.io"; 
let updatedUrl = currentUrl.replace("https://neoneuron.github.io", "");
if (currentUrl.length == updatedUrl.length && currentUrl.startsWith("http://127.0.0.1")) {
  const otherSiteUrl = siteUrl.replace("localhost", "127.0.0.1");
  updatedUrl = currentUrl.replace(otherSiteUrl + "", "");
}
if ("zh-cn".length > 0) {
  updatedUrl = updatedUrl.replace("/zh-cn", "");
}
// get the ninja-keys element
const ninja = document.querySelector('ninja-keys');

// add the home and posts menu items
ninja.data = [{
    id: "nav-简介",
    title: "简介",
    section: "导航栏",
    handler: () => {
      window.location.href = "/zh-cn/";
    },
  },{id: "nav-简历",
          title: "简历",
          description: "",
          section: "导航栏",
          handler: () => {
            window.location.href = "/zh-cn/cv/";
          },
        },{id: "nav-论文",
          title: "论文",
          description: "一些小论文",
          section: "导航栏",
          handler: () => {
            window.location.href = "/zh-cn/publications/";
          },
        },{id: "nav-教学",
          title: "教学",
          description: "一些教学资料。",
          section: "导航栏",
          handler: () => {
            window.location.href = "/zh-cn/teaching/";
          },
        },{id: "nav-博客",
          title: "博客",
          description: "一点点胡思乱想的痕迹",
          section: "导航栏",
          handler: () => {
            window.location.href = "/zh-cn/blog/";
          },
        },{id: "nav-代码",
          title: "代码",
          description: "欢迎使用，如有任何问题，请给我提issue。",
          section: "导航栏",
          handler: () => {
            window.location.href = "/zh-cn/repositories/";
          },
        },{id: "post-在macos上使用gcc编译boost",
      
        title: '在macOS上使用gcc编译boost <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',
      
      description: "",
      section: "Posts",
      handler: () => {
        
          window.open("https://neoneuron.notion.site/Compiling-boost-using-gcc-on-macOS-53f9e1af73844c9da18c405cabff4b5c", "_blank");
        
      },
    },{id: "post-deepdendrite安装指南",
      
        title: 'DeepDendrite安装指南 <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',
      
      description: "",
      section: "Posts",
      handler: () => {
        
          window.open("https://neoneuron.notion.site/Install-DeepDendrite-b72dbcda941a439fb8b5bf0af1086e86?pvs=4", "_blank");
        
      },
    },{id: "post-神经元网络fokker-planck方程",
      
        title: "神经元网络Fokker Planck方程",
      
      description: "",
      section: "Posts",
      handler: () => {
        
          window.location.href = "/zh-cn/blog/2023/FPE-and-NMM/";
        
      },
    },{id: "post-the-role-of-population-structure-in-computations-through-neural-dynamics",
      
        title: "The role of population structure in computations through neural dynamics",
      
      description: "It has been widely recorded that the population neuronal activities pocess the low dimensional manifold in multiple brain regions, especially PFC. The origin of low dimensional dynamics and the relation between the dynamical properties and the network structures remain open questions. One of the potential solutions is that low dimensional dynamics is generated by low-rank network architectures. This work trained low-rank recurrent neural networks to perform 5 distinct cognitive tasks respectively, and theoretically analyzed the network dynamics performing computation for each task. Their work showed that very few ranks (1-2) of network structure are actually required to well perform those cognitive tasks. For those tasks with flexible input-target mapping, multiple cell-types (sub-populations) are necessary to perform tasks. Overall, their theory of low-rank RNN can extract the effective latent dynamics for computation, and furthermore provide a framework to networks with multitasking ability.",
      section: "Posts",
      handler: () => {
        
          window.location.href = "/zh-cn/blog/2022/KaiChen1/";
        
      },
    },{id: "post-context-dependent-computation-by-recurrent-dynamics-in-prefrontal-cortex",
      
        title: "Context-dependent computation by recurrent dynamics in prefrontal cortex",
      
      description: "Mante et. al. showed how neurons with complex response coordinate together to do computations of selective integrations in monkey PFC. They trained an siRNN to model the psychophysical behavior of monkeys. By analyzing the modeled siRNN using theory of linear dynamical system, the response of siRNN fits almost perfectly with monkey data in the population level. Furthermore, siRNN produced a novel mechanism to unify selection and integration in a single circuit in terms of line attractor and selection vector.",
      section: "Posts",
      handler: () => {
        
          window.location.href = "/zh-cn/blog/2021/KaiChen4/";
        
      },
    },{id: "post-nestml安装教程",
      
        title: "NESTML安装教程",
      
      description: "",
      section: "Posts",
      handler: () => {
        
          window.location.href = "/zh-cn/blog/2021/install-nestml/";
        
      },
    },{id: "post-learning-function-from-structure-in-neuromorphic-networks",
      
        title: "Learning function from structure in neuromorphic networks",
      
      description: "Human brain can perform various of cognitive tasks and is able to flexibly learn new tasks without interfering other tasks. Whether and how the learning and computing capability is inherited from the brain connectomes remains unknown. This work tried to link the learning function and brain connectome in the framework of reservoir computing. They showed that the brain connectome outperform random network at crtical dynamical regime. Futhermore, they found that functional parcellation helps regulate the information flow which might facilitate the cognitive computation in brain",
      section: "Posts",
      handler: () => {
        
          window.location.href = "/zh-cn/blog/2021/KaiChen3/";
        
      },
    },{id: "post-one-step-back-two-steps-forward-interference-and-learning-in-recurrent-neural-networks",
      
        title: "One Step Back, Two Steps Forward: Interference and Learning in Recurrent Neural Networks...",
      
      description: "Catastrophic forgetting is a key issue in continual learning paradigm. Training algorithms, like FORCE, seem to be able to bypass this to some extent. Chen and Barak applied fixed point analysis to explicitly show the change of fixed point structure of networks during training in continual learning scenario. Their work provide intuitions about how learning algorithm and the order of task sequence affect the training in continual learning.",
      section: "Posts",
      handler: () => {
        
          window.location.href = "/zh-cn/blog/2021/KaiChen2/";
        
      },
    },{id: "post-universality-and-individuality-in-neural-dynamics-across-large-populations-of-recurrent-networks",
      
        title: "Universality and individuality in neural dynamics across large populations of recurrent networks",
      
      description: "Multi-solution is a prominant feature of ANNs (DNNs/RNNs) when training to perform certain tasks. Is there any common feature between different solutions remains an open questions. This works found that the topology of fixed points of trained network is the universally shared between different network architectures and realizations when those networks are trained for the same task. Further, they demonstrated the topological structure of fixed points of networks indeed interprets computation mechanism of trained networks.",
      section: "Posts",
      handler: () => {
        
          window.location.href = "/zh-cn/blog/2021/KaiChen1/";
        
      },
    },{id: "post-路由器桥接配置",
      
        title: "路由器桥接配置",
      
      description: "",
      section: "Posts",
      handler: () => {
        
          window.location.href = "/zh-cn/blog/2021/router-bridge/";
        
      },
    },{id: "post-generating-coherent-patterns-of-activity-from-chaotic-neural-networks",
      
        title: "Generating Coherent Patterns of Activity from Chaotic Neural Networks",
      
      description: "Sussillo and Abbott improved the echo-state network (ESN) with FORCE algorithm, which is more robust again noise and perturbations. They also provided the analysis of train dynamics and reverse-engineering of network dynamics for reservoir network generating coherent patterns.",
      section: "Posts",
      handler: () => {
        
          window.location.href = "/zh-cn/blog/2020/KaiChen1/";
        
      },
    },{id: "news-my-phd-qualification-is-passed-smile",
          title: 'My PhD qualification is passed. :smile:',
          description: "",
          section: "News",},{id: "news-新海报和口头汇报发表在-cccn2021-sparkles-smile",
          title: '新海报和口头汇报发表在 CCCN2021 :sparkles: :smile:',
          description: "",
          section: "News",handler: () => {
              window.location.href = "/zh-cn/news/2021-06-CCCN_poster/";
            },},{id: "news-my-phd-thesis-proposal-is-passed",
          title: 'My PhD thesis proposal is passed.',
          description: "",
          section: "News",},{id: "news-新海报发表在-cccn2022-sparkles-smile",
          title: '新海报发表在 CCCN2022 :sparkles: :smile:',
          description: "",
          section: "News",handler: () => {
              window.location.href = "/zh-cn/news/2022-06-CCCN_poster/";
            },},{id: "news-csiam-2022-学生论坛口头汇报-中文",
          title: 'CSIAM 2022 学生论坛口头汇报(中文)',
          description: "",
          section: "News",handler: () => {
              window.location.href = "/zh-cn/news/2022-11-CSIAM_oral/";
            },},{id: "news-美国工业与应用数学学会应用动力系统分会-2023-口头报告-sparkles-smile",
          title: '美国工业与应用数学学会应用动力系统分会 2023 口头报告 :sparkles: :smile:',
          description: "",
          section: "News",handler: () => {
              window.location.href = "/zh-cn/news/2023-05-SIAM_oral/";
            },},{id: "news-新海报入选-cns2023-sparkles-smile",
          title: '新海报入选 CNS2023 :sparkles: :smile:',
          description: "",
          section: "News",handler: () => {
              window.location.href = "/zh-cn/news/2023-07-CNS_poster/";
            },},{id: "news-新海报入选-iciam2023-sparkles-smile",
          title: '新海报入选 ICIAM2023 :sparkles: :smile:',
          description: "",
          section: "News",handler: () => {
              window.location.href = "/zh-cn/news/2023-08-ICIAM_poster/";
            },},{id: "news-关于-因果推断网络重构-新文章发表在美国科学院院刊-pnas-sparkles-smile",
          title: '关于“因果推断网络重构“新文章发表在美国科学院院刊（PNAS） :sparkles: :smile:',
          description: "",
          section: "News",handler: () => {
              window.location.href = "/zh-cn/news/2024-03-PNAS_paper/";
            },},{id: "news-新海报入选2024中国神经科学年会",
          title: '新海报入选2024中国神经科学年会',
          description: "",
          section: "News",handler: () => {
              window.location.href = "/zh-cn/news/2024-09-CNS_poster/";
            },},{id: "news-多脑区循环神经网络训练框架被cosyne2025接收-将作为墙报展示-tada",
          title: '多脑区循环神经网络训练框架被COSYNE2025接收，将作为墙报展示。:tada:',
          description: "",
          section: "News",},{id: "news-新海报入选第四届神经计算青年研讨会",
          title: '新海报入选第四届神经计算青年研讨会',
          description: "",
          section: "News",handler: () => {
              window.location.href = "/zh-cn/news/2025-01-SYNCB_poster/";
            },},{
        id: 'social-email',
        title: '发邮件',
        section: 'Socials',
        handler: () => {
          window.open("mailto:%6B%63%68%65%6E%35%31%33@%6F%75%74%6C%6F%6F%6B.%63%6F%6D", "_blank");
        },
      },{
        id: 'social-github',
        title: 'GitHub',
        section: 'Socials',
        handler: () => {
          window.open("https://github.com/Neoneuron", "_blank");
        },
      },{
        id: 'social-linkedin',
        title: 'LinkedIn',
        section: 'Socials',
        handler: () => {
          window.open("https://www.linkedin.com/in/kai-chen-a35666a6", "_blank");
        },
      },{
        id: 'social-orcid',
        title: 'ORCID',
        section: 'Socials',
        handler: () => {
          window.open("https://orcid.org/0009-0004-3834-9504", "_blank");
        },
      },{
        id: 'social-rss',
        title: 'RSS Feed',
        section: 'Socials',
        handler: () => {
          window.open("/feed.xml", "_blank");
        },
      },{
        id: 'social-scholar',
        title: 'Google Scholar',
        section: 'Socials',
        handler: () => {
          window.open("https://scholar.google.com/citations?user=TzcYWrUAAAAJ", "_blank");
        },
      },{
        id: 'social-x',
        title: 'X',
        section: 'Socials',
        handler: () => {
          window.open("https://twitter.com/kchen513", "_blank");
        },
      },{
          id: 'lang-en-us',
          title: 'en-us',
          section: '语言',
          handler: () => {
            window.location.href = "" + updatedUrl;
          },
        },{
      id: 'light-theme',
      title: '切换日间模式',
      description: '切换日间模式',
      section: '主题',
      handler: () => {
        setThemeSetting("light");
      },
    },
    {
      id: 'dark-theme',
      title: '切换夜间模式',
      description: '切换夜间模式',
      section: '主题',
      handler: () => {
        setThemeSetting("dark");
      },
    },
    {
      id: 'system-theme',
      title: '切换系统主题模式',
      description: '切换系统主题模式',
      section: '主题',
      handler: () => {
        setThemeSetting("system");
      },
    },];